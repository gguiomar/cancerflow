{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "\n",
    "# my bibs\n",
    "from cnn_net_bib import * \n",
    "from cnn_plot_bib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters1 = 16         # There are 16 of these filters.\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\n",
    "num_filters2 = 36         # There are 36 of these filters.\n",
    "\n",
    "# Fully-connected layer.\n",
    "fc_size = 128             # Number of neurons in fully-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Loading the MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)\n",
    "\n",
    "data.test.cls = np.argmax(data.test.labels, axis=1)\n",
    "\n",
    "# MNIST data dimensionality\n",
    "\n",
    "img_size = 28\n",
    "img_size_flat = img_size * img_size\n",
    "img_shape = (img_size, img_size)\n",
    "num_channels = 1 # grey scale\n",
    "num_classes = 10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11c8f3f98>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11c907048>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x11c9070b8>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_batch, y_true_batch = data.train.next_batch(train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:   7.8%\n",
      "Optimization Iteration:    101, Training Accuracy:  62.5%\n",
      "Optimization Iteration:    201, Training Accuracy:  82.8%\n",
      "Optimization Iteration:    301, Training Accuracy:  85.9%\n",
      "Optimization Iteration:    401, Training Accuracy:  90.6%\n",
      "Optimization Iteration:    501, Training Accuracy:  90.6%\n",
      "Optimization Iteration:    601, Training Accuracy:  95.3%\n",
      "Optimization Iteration:    701, Training Accuracy:  92.2%\n",
      "Optimization Iteration:    801, Training Accuracy:  92.2%\n",
      "Optimization Iteration:    901, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   1001, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   1101, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1201, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1301, Training Accuracy:  92.2%\n",
      "Optimization Iteration:   1401, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1501, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   1601, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   1701, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1801, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   1901, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   2001, Training Accuracy:  90.6%\n",
      "Optimization Iteration:   2101, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   2201, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2301, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   2401, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2501, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   2601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   2701, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   2801, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   2901, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   3001, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   3101, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   3201, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3301, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   3401, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3501, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   3601, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   3701, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   3901, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4001, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4101, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4201, Training Accuracy:  96.9%\n",
      "Optimization Iteration:   4301, Training Accuracy:  93.8%\n",
      "Optimization Iteration:   4401, Training Accuracy:  95.3%\n",
      "Optimization Iteration:   4501, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4601, Training Accuracy: 100.0%\n",
      "Optimization Iteration:   4701, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4801, Training Accuracy:  98.4%\n",
      "Optimization Iteration:   4901, Training Accuracy: 100.0%\n",
      "Time usage: 0:08:02\n"
     ]
    }
   ],
   "source": [
    "# placeholder variables \n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')\n",
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)\n",
    "\n",
    "# network architecture\n",
    "\n",
    "layer_conv1, weights_conv1 = new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)\n",
    "\n",
    "layer_conv2, weights_conv2 = new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)\n",
    "\n",
    "layer_flat, num_features = flatten_layer(layer_conv2)\n",
    "\n",
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)\n",
    "\n",
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)\n",
    "\n",
    "\n",
    "\n",
    "# network predictions\n",
    "\n",
    "y_pred = tf.nn.softmax(layer_fc2)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "\n",
    "# cost function and optimization measures\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2, labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "# performance measures\n",
    "\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# running the network\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "train_batch_size = 64\n",
    "\n",
    "# Counter for total number of iterations performed so far.\n",
    "\n",
    "# optimization algorithm\n",
    "total_iterations = 0\n",
    "def optimize(num_iterations):\n",
    "\n",
    "\t# Ensure we update the global variable rather than a local copy.\n",
    "\tglobal total_iterations\n",
    "\n",
    "\t# Start-time used for printing time-usage below.\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\tfor i in range(total_iterations,\n",
    "\t               total_iterations + num_iterations):\n",
    "\n",
    "\t    # Get a batch of training examples.\n",
    "\t    # x_batch now holds a batch of images and\n",
    "\t    # y_true_batch are the true labels for those images.\n",
    "\t    x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "\n",
    "\t    # Put the batch into a dict with the proper names\n",
    "\t    # for placeholder variables in the TensorFlow graph.\n",
    "\t    feed_dict_train = {x: x_batch,\n",
    "\t                       y_true: y_true_batch}\n",
    "\n",
    "\t    # Run the optimizer using this batch of training data.\n",
    "\t    # TensorFlow assigns the variables in feed_dict_train\n",
    "\t    # to the placeholder variables and then runs the optimizer.\n",
    "\t    session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "\t    # Print status every 100 iterations.\n",
    "\t    if i % 100 == 0:\n",
    "\t        # Calculate the accuracy on the training-set.\n",
    "\t        acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "\t        # Message for printing.\n",
    "\t        msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "\t        # Print it.\n",
    "\t        print(msg.format(i + 1, acc))\n",
    "\n",
    "\t# Update the total number of iterations performed.\n",
    "\ttotal_iterations += num_iterations\n",
    "\n",
    "\t# Ending time.\n",
    "\tend_time = time.time()\n",
    "\n",
    "\t# Difference between start and end-times.\n",
    "\ttime_dif = end_time - start_time\n",
    "\n",
    "\t# Print the time-usage.\n",
    "\tprint(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
    "\n",
    "optimize(num_iterations = 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
